{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Discovering_the_Star_Trek_Universe_with_spaCy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "9NorCU49mM0m",
        "ytnXaZ6BF5Hg",
        "EH4F9UbXBdYK",
        "I3njzb5e9vTW",
        "RLH7xrNk_pCC",
        "n2TlKdoW_UEb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mer0mingian/statistics_for_data_science/blob/master/Discovering_the_Star_Trek_Universe_with_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8b9OUAuLD1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvTspzVcBC3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Hello Universe!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NorCU49mM0m",
        "colab_type": "text"
      },
      "source": [
        " # 1. Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byaYOb0HB4Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load small spacy model, alternative install \"en_core_web_lg\" with word vectors\n",
        "nlp = spacy.load(\"en\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6SFpuQXB9G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"I'm done here on planet Earth. Ready to beam, Miles O'Brien!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnSVpts5CDHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Text tokenizer\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2wFnJHSGoVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sentence tokenizer\n",
        "for sent in doc.sents:\n",
        "  print()\n",
        "  print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytnXaZ6BF5Hg",
        "colab_type": "text"
      },
      "source": [
        "# 2. Named Entity Recognition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSWormCqE0o2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JowRfhnfKZua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate over named entities and show text and label (type of entity)\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \" - \", ent.label_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59N6BpMf_Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Task: Parse the sentence \"United Federation of Planets is based on Earth in San Francisco\" \n",
        "## with the NLP pipeline. Which entities are in this sentence?\n",
        "\n",
        "\n",
        "doc = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5bmLyQ5Mshs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy.displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH4F9UbXBdYK",
        "colab_type": "text"
      },
      "source": [
        "# 3. Part of Speech Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTAzWxjqfU-E",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.startrek.com/sites/default/files/styles/content_full/public/images/inline/2019-01/a105e08e3af3eda31c9b970fcb04f265.jpg?itok=MxAB76pF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqe9P2gTMwKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"There is a fire on deck one!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E25VexnaJXFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for token in doc:\n",
        "  print(token.text, \"-\", token.lemma_, \"-\", token.pos_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Bf-V8zNWzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNHw-5x7yBqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy.explain(---)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKB14xZTbhCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"Good. They can't fire when they're cloaked.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbHpwHTkbwmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3njzb5e9vTW",
        "colab_type": "text"
      },
      "source": [
        "# 4. Matcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSchjBHV-2IO",
        "colab_type": "text"
      },
      "source": [
        "[Open Matcher Demo](https://explosion.ai/demos/matcher?text=We%27re%20now%20at%20warp%20four%20point%20three.%0AMr.%20Crusher%2C%20warp%20eight%2C%20engange!&model=en_core_web_sm&pattern=%5B%5D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABmXNFVsTFYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "pattern = []\n",
        "matcher.add(\"WARP\", None, pattern)\n",
        "\n",
        "doc = nlp(u\"We're now at warp nine point three.\")\n",
        "\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]  # The matched span\n",
        "    print(span)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLH7xrNk_pCC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 5. Representations and similarities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptYFav66_58d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"This is Data's cat. He does not have a dog!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEVPtNEf_-fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Token has a vector (word embedding)\n",
        "doc[0].vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2HxGdfIUeEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(doc[4], doc[11])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcpMPrjWUp49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating cosine similarity of vectors and compare\n",
        "for word in doc:\n",
        "  print(word.text, \" - \", doc[4].text, \": \", word.similarity(doc[4]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2TlKdoW_UEb",
        "colab_type": "text"
      },
      "source": [
        "# 6. Using custom models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF4iUiuNAaQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install https://github.com/chssch/spacy-models/raw/master/en_tng_ner-0.0.1.tar.gz\n",
        "!spacy link en_tng_ner en_tng_ner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkONR58KdK-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_tng_ner\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-20dOXyZdNkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"The Vulcan ship arrived at Earth\")\n",
        "displacy.render(doc, style='ent', jupyter=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhjRA5bBdrb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(\"This material can be found on Vulcan\")\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EbJsfkRh3iA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/RTrek/startrekTNGdataset/raw/master/data2/TNG.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8mlXo6Ve3Qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(\"TNG.csv\")\n",
        "    # Only keep rows with a person as speaker\n",
        "    df = df.dropna(subset=['who'])\n",
        "    df = df.fillna(\"\")\n",
        "    # Normalize\n",
        "    df.who = df.who.apply(lambda x: x.replace(\"V.O.\", \"\").strip())\n",
        "    df.text = df.text.apply(lambda x: x.strip())\n",
        "    # Only keep main characters\n",
        "    df = df.query('who == \"PICARD\" or who == \"RIKER\" or who == \"WORF\" or who == \"DATA\" or who == \"BEVERLY\" or who == \"TROI\"')\n",
        "    df = df.reset_index()\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGvGYWq7h0Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extra: using nlp.pipe for batch processing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQQwIN2Vh-3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch processing\n",
        "df_subset = get_data().sample(frac=0.01)\n",
        "for doc in nlp.pipe((it.text for _, it in df_subset.iterrows())):\n",
        "    if doc.ents:\n",
        "        displacy.render(doc, style='ent', jupyter=True, options={\"ents\": [\"ALIEN_SPECIES\", \"SPACE_DESTINATION\"], \"colors\": {\"ALIEN_SPECIES\": \"#AA3939\",  \"SPACE_DESTINATION\": \"#2D882D\"}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N__mynE1icjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}